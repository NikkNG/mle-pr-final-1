"""
Content-Based Filtering models for recommendation system
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.decomposition import TruncatedSVD
import warnings
warnings.filterwarnings('ignore')


class ContentBasedRecommender:
    """
    Content-Based Recommender using item features
    """
    
    def __init__(self, 
                 similarity_metric: str = 'cosine',
                 n_components: Optional[int] = None,
                 random_state: int = 42):
        """
        Initialize Content-Based Recommender
        
        Args:
            similarity_metric: Similarity metric ('cosine', 'euclidean')
            n_components: Number of components for dimensionality reduction (optional)
            random_state: Random seed
        """
        self.similarity_metric = similarity_metric
        self.n_components = n_components
        self.random_state = random_state
        
        # –ú–æ–¥–µ–ª—å components
        self.item_features = None
        self.item_similarity_matrix = None
        self.user_profiles = None
        self.item_encoder = None
        self.feature_scaler = StandardScaler()
        self.svd = None
        
        # Fitted flag
        self.is_fitted = False
    
    def fit(self, 
            user_item_matrix: csr_matrix,
            item_features: Dict[str, Union[np.ndarray, Dict]],
            metadata: Dict) -> 'ContentBasedRecommender':
        """
        Fit Content-Based model
        
        Args:
            user_item_matrix: User-item interaction matrix
            item_features: Dictionary with item features
            metadata: Metadata dictionary
            
        Returns:
            Self for method chaining
        """
        print("ü§ñ –û–±—É—á–µ–Ω–∏–µ Content-Based –º–æ–¥–µ–ª–∏...")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ metadata
        self.item_encoder = metadata['item_encoder']
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¢–æ–≤–∞—Ä features
        self.item_features = self._process_features(item_features)
        print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {self.item_features.shape[0]} —Ç–æ–≤–∞—Ä–æ–≤ —Å {self.item_features.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        
        # Apply dimensionality reduction if specified
        if self.n_components and self.n_components < self.item_features.shape[1]:
            print(f"üìâ –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ SVD: {self.item_features.shape[1]} -> {self.n_components} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç")
            self.svd = TruncatedSVD(n_components=self.n_components, random_state=self.random_state)
            self.item_features = self.svd.fit_transform(self.item_features)
        
        # –†–∞—Å—á–µ—Ç –¢–æ–≤–∞—Ä –°—Ö–æ–∂–µ—Å—Ç—å –ú–∞—Ç—Ä–∏—Ü–∞
        self.item_similarity_matrix = self._calculate_similarity_matrix()
        print(f"üìä –°–æ–∑–¥–∞–Ω–∞ –º–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤: {self.item_similarity_matrix.shape}")
        
        # –°–±–æ—Ä–∫–∞ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å profiles
        self.user_profiles = self._build_user_profiles(user_item_matrix)
        print(f"üìä –°–æ–∑–¥–∞–Ω–æ {len(self.user_profiles)} –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
        
        self.is_fitted = True
        print("‚úÖ Content-Based –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        
        return self
    
    def _process_features(self, item_features: Dict) -> np.ndarray:
        """Process item features into numerical matrix"""
        print("üîß –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤...")
        
        # Get –¢–æ–≤–∞—Ä IDs
        item_ids = self.item_encoder.classes_
        n_items = len(item_ids)
        
        feature_vectors = []
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ TF-IDF features if available
        if 'tfidf' in item_features and item_features['tfidf']:
            print("üìù –û–±—Ä–∞–±–æ—Ç–∫–∞ TF-IDF –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
            tfidf_features = item_features['tfidf']
            
            # –°–æ–∑–¥–∞–Ω–∏–µ TF-IDF –ú–∞—Ç—Ä–∏—Ü–∞
            tfidf_matrix = []
            for item_id in item_ids:
                if str(item_id) in tfidf_features:
                    tfidf_matrix.append(tfidf_features[str(item_id)])
                else:
                    # Zero –í–µ–∫—Ç–æ—Ä for items without features
                    feature_dim = len(next(iter(tfidf_features.values())))
                    tfidf_matrix.append(np.zeros(feature_dim))
            
            tfidf_matrix = np.array(tfidf_matrix)
            feature_vectors.append(tfidf_matrix)
            print(f"   TF-IDF: {tfidf_matrix.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ö–∞—Ç–µ–≥–æ—Ä–∏—è features if available
        if 'categories' in item_features and item_features['categories']:
            print("üè∑Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π...")
            categories = item_features['categories']
            
            # Get unique categories
            unique_categories = list(set(categories.values()))
            category_encoder = LabelEncoder()
            category_encoder.fit(unique_categories)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ one-hot encoded –ö–∞—Ç–µ–≥–æ—Ä–∏—è features
            category_matrix = np.zeros((n_items, len(unique_categories)))
            for i, item_id in enumerate(item_ids):
                if str(item_id) in categories:
                    category_idx = category_encoder.transform([categories[str(item_id)]])[0]
                    category_matrix[i, category_idx] = 1
            
            feature_vectors.append(category_matrix)
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: {category_matrix.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ all features
        if feature_vectors:
            combined_features = np.hstack(feature_vectors)
        else:
            # –°–æ–∑–¥–∞–Ω–∏–µ –°–ª—É—á–∞–π–Ω–∞—è features if no features available
            print("‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, —Å–æ–∑–¥–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏")
            combined_features = np.random.rand(n_items, 50)
        
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        combined_features = self.feature_scaler.fit_transform(combined_features)
        
        return combined_features
    
    def _calculate_similarity_matrix(self) -> np.ndarray:
        """Calculate item similarity matrix"""
        print(f"üìä –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ—Ç–æ–¥–æ–º '{self.similarity_metric}'...")
        
        if self.similarity_metric == 'cosine':
            similarity_matrix = cosine_similarity(self.item_features)
        elif self.similarity_metric == 'euclidean':
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ distances to similarities
            distances = euclidean_distances(self.item_features)
            max_distance = np.max(distances)
            similarity_matrix = 1 - (distances / max_distance)
        else:
            raise ValueError(f"Unknown similarity metric: {self.similarity_metric}")
        
        return similarity_matrix
    
    def _build_user_profiles(self, user_item_matrix: csr_matrix) -> Dict[int, np.ndarray]:
        """Build user profiles based on item interactions"""
        print("üë§ –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª–µ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...")
        
        user_profiles = {}
        
        for user_idx in range(user_item_matrix.shape[0]):
            # Get –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å interactions
            user_items = user_item_matrix[user_idx].nonzero()[1]
            user_ratings = user_item_matrix[user_idx].data
            
            if len(user_items) > 0:
                # Weight –¢–æ–≤–∞—Ä features by interaction strength
                weighted_features = []
                total_weight = 0
                
                for item_idx, rating in zip(user_items, user_ratings):
                    if item_idx < len(self.item_features):
                        weighted_features.append(self.item_features[item_idx] * rating)
                        total_weight += rating
                
                if weighted_features and total_weight > 0:
                    # Average weighted features
                    user_profile = np.sum(weighted_features, axis=0) / total_weight
                    user_profiles[user_idx] = user_profile
        
        return user_profiles
    
    def recommend_for_user(self, 
                          user_idx: int,
                          n_recommendations: int = 10,
                          filter_already_liked: bool = True,
                          user_item_matrix: Optional[csr_matrix] = None) -> List[Tuple[int, float]]:
        """
        Generate recommendations for a user
        
        Args:
            user_idx: User index
            n_recommendations: Number of recommendations
            filter_already_liked: Whether to filter items user already interacted with
            user_item_matrix: User-item matrix (for filtering)
            
        Returns:
            List of (item_idx, score) tuples
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before making recommendations")
        
        if user_idx not in self.user_profiles:
            # Cold –ó–∞–ø—É—Å–∫: –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è popular items or –°–ª—É—á–∞–π–Ω–∞—è items
            return self._handle_cold_start_user(n_recommendations)
        
        # Get –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å profile
        user_profile = self.user_profiles[user_idx]
        
        # –†–∞—Å—á–µ—Ç similarities with all items
        item_scores = cosine_similarity([user_profile], self.item_features)[0]
        
        # Get items to –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è out
        items_to_filter = set()
        if filter_already_liked and user_item_matrix is not None:
            items_to_filter = set(user_item_matrix[user_idx].nonzero()[1])
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ items by –û—Ü–µ–Ω–∫–∞
        item_indices = np.argsort(item_scores)[::-1]
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è and collect recommendations
        recommendations = []
        for item_idx in item_indices:
            if item_idx not in items_to_filter:
                recommendations.append((item_idx, float(item_scores[item_idx])))
                if len(recommendations) >= n_recommendations:
                    break
        
        return recommendations
    
    def get_similar_items(self, 
                         item_idx: int,
                         n_similar: int = 10) -> List[Tuple[int, float]]:
        """
        Find similar items
        
        Args:
            item_idx: Item index
            n_similar: Number of similar items
            
        Returns:
            List of (item_idx, similarity_score) tuples
        """
        if not self.is_fitted:
            raise ValueError("Model must be fitted before finding similar items")
        
        if item_idx >= len(self.item_similarity_matrix):
            raise ValueError(f"Item index {item_idx} out of range")
        
        # Get –°—Ö–æ–∂–µ—Å—Ç—å scores
        similarities = self.item_similarity_matrix[item_idx]
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ by –°—Ö–æ–∂–µ—Å—Ç—å (excluding the –¢–æ–≤–∞—Ä itself)
        similar_indices = np.argsort(similarities)[::-1]
        
        # Collect similar items
        similar_items = []
        for idx in similar_indices:
            if idx != item_idx:  # Exclude the item itself
                similar_items.append((idx, float(similarities[idx])))
                if len(similar_items) >= n_similar:
                    break
        
        return similar_items
    
    def _handle_cold_start_user(self, n_recommendations: int) -> List[Tuple[int, float]]:
        """Handle cold start users"""
        # Return items with highest average –ü—Ä–∏–∑–Ω–∞–∫ values (–ü—Ä–æ–∫—Å–∏ for –ü–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å)
        item_scores = np.mean(self.item_features, axis=1)
        top_items = np.argsort(item_scores)[::-1][:n_recommendations]
        
        return [(int(item_idx), float(item_scores[item_idx])) for item_idx in top_items]
    
    def get_model_params(self) -> Dict:
        """Get model parameters"""
        return {
            'similarity_metric': self.similarity_metric,
            'n_components': self.n_components,
            'random_state': self.random_state
        }


class TFIDFRecommender:
    """
    TF-IDF based Content Recommender
    """
    
    def __init__(self,
                 max_features: int = 1000,
                 ngram_range: Tuple[int, int] = (1, 2),
                 min_df: int = 2,
                 max_df: float = 0.8):
        """
        Initialize TF-IDF Recommender
        
        Args:
            max_features: Maximum number of features
            ngram_range: N-gram range for TF-IDF
            min_df: Minimum document frequency
            max_df: Maximum document frequency
        """
        self.max_features = max_features
        self.ngram_range = ngram_range
        self.min_df = min_df
        self.max_df = max_df
        
        # –ú–æ–¥–µ–ª—å components
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=max_features,
            ngram_range=ngram_range,
            min_df=min_df,
            max_df=max_df,
            stop_words='english',
            lowercase=True
        )
        
        self.item_features = None
        self.item_similarity_matrix = None
        self.item_encoder = None
        self.is_fitted = False
    
    def fit(self, 
            item_properties_df: pd.DataFrame,
            metadata: Dict) -> 'TFIDFRecommender':
        """
        Fit TF-IDF model
        
        Args:
            item_properties_df: Item properties DataFrame
            metadata: Metadata dictionary
            
        Returns:
            Self for method chaining
        """
        print("ü§ñ –û–±—É—á–µ–Ω–∏–µ TF-IDF –º–æ–¥–µ–ª–∏...")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ metadata
        self.item_encoder = metadata['item_encoder']
        item_ids = self.item_encoder.classes_
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¢–æ–≤–∞—Ä text descriptions
        item_texts = self._create_item_texts(item_properties_df, item_ids)
        
        # –û–±—É—á–µ–Ω–∏–µ TF-IDF vectorizer
        self.item_features = self.tfidf_vectorizer.fit_transform(item_texts)
        print(f"üìä TF-IDF –º–∞—Ç—Ä–∏—Ü–∞: {self.item_features.shape}")
        
        # –†–∞—Å—á–µ—Ç –°—Ö–æ–∂–µ—Å—Ç—å –ú–∞—Ç—Ä–∏—Ü–∞
        self.item_similarity_matrix = cosine_similarity(self.item_features)
        print(f"üìä –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: {self.item_similarity_matrix.shape}")
        
        self.is_fitted = True
        print("‚úÖ TF-IDF –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞")
        
        return self
    
    def _create_item_texts(self, 
                          item_properties_df: pd.DataFrame,
                          item_ids: np.ndarray) -> List[str]:
        """Create text descriptions for items"""
        print("üìù –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤...")
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –°–≤–æ–π—Å—Ç–≤–∞ by –¢–æ–≤–∞—Ä
        item_texts = []
        
        for item_id in item_ids:
            item_props = item_properties_df[
                item_properties_df['itemid'].astype(str) == str(item_id)
            ]
            
            if not item_props.empty:
                # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ all –°–≤–æ–π—Å—Ç–≤–∞ and values
                text_parts = []
                for _, row in item_props.iterrows():
                    prop_text = f"{row['property']} {row['value']}"
                    text_parts.append(prop_text)
                
                item_text = ' '.join(text_parts)
            else:
                # Empty text for items without –°–≤–æ–π—Å—Ç–≤–∞
                item_text = ""
            
            item_texts.append(item_text)
        
        return item_texts
    
    def get_similar_items(self, 
                         item_idx: int,
                         n_similar: int = 10) -> List[Tuple[int, float]]:
        """Find similar items using TF-IDF"""
        if not self.is_fitted:
            raise ValueError("Model must be fitted before finding similar items")
        
        if item_idx >= len(self.item_similarity_matrix):
            raise ValueError(f"Item index {item_idx} out of range")
        
        # Get –°—Ö–æ–∂–µ—Å—Ç—å scores
        similarities = self.item_similarity_matrix[item_idx]
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ by –°—Ö–æ–∂–µ—Å—Ç—å (excluding the –¢–æ–≤–∞—Ä itself)
        similar_indices = np.argsort(similarities)[::-1]
        
        # Collect similar items
        similar_items = []
        for idx in similar_indices:
            if idx != item_idx:  # Exclude the item itself
                similar_items.append((idx, float(similarities[idx])))
                if len(similar_items) >= n_similar:
                    break
        
        return similar_items


class ContentBasedEvaluator:
    """
    Evaluator for content-based models
    """
    
    def __init__(self, 
                 train_matrix: csr_matrix,
                 test_matrix: csr_matrix):
        """
        Initialize evaluator
        
        Args:
            train_matrix: Training user-item matrix
            test_matrix: Test user-item matrix
        """
        self.train_matrix = train_matrix
        self.test_matrix = test_matrix
    
    def evaluate_model(self,
                      model: Union[ContentBasedRecommender, TFIDFRecommender],
                      n_recommendations: int = 10,
                      k_values: List[int] = [5, 10, 20]) -> Dict[str, float]:
        """
        Evaluate content-based model
        
        Args:
            model: Trained model
            n_recommendations: Number of recommendations to generate
            k_values: List of k values for evaluation
            
        Returns:
            Dictionary with evaluation metrics
        """
        from .metrics import RecommendationMetrics
        
        print(f"üìä –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ {model.__class__.__name__}...")
        
        # Get –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ users
        test_users = []
        test_items_per_user = {}
        
        for user_idx in range(self.test_matrix.shape[0]):
            user_test_items = self.test_matrix[user_idx].nonzero()[1]
            if len(user_test_items) > 0:
                test_users.append(user_idx)
                test_items_per_user[user_idx] = user_test_items.tolist()
        
        print(f"üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(test_users)} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è—Ö...")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è recommendations
        y_true = []
        y_pred = []
        
        for user_idx in test_users:
            try:
                if hasattr(model, 'recommend_for_user'):
                    recommendations = model.recommend_for_user(
                        user_idx,
                        n_recommendations=max(k_values),
                        filter_already_liked=True,
                        user_item_matrix=self.train_matrix
                    )
                    rec_items = [item_idx for item_idx, score in recommendations]
                else:
                    # For models that don't have –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å recommendations
                    rec_items = []
                
                y_true.append(test_items_per_user[user_idx])
                y_pred.append(rec_items)
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_idx}: {e}")
                y_true.append(test_items_per_user[user_idx])
                y_pred.append([])
        
        # –†–∞—Å—á–µ—Ç metrics
        metrics_calculator = RecommendationMetrics()
        metrics = metrics_calculator.calculate_all_metrics(
            y_true=y_true,
            y_pred=y_pred,
            k_values=k_values,
            total_items=self.train_matrix.shape[1]
        )
        
        return metrics


def create_content_based_models() -> Dict[str, Union[ContentBasedRecommender, TFIDFRecommender]]:
    """
    Create content-based models with different configurations
    
    Returns:
        Dictionary of models
    """
    models = {
        'content_cosine': ContentBasedRecommender(similarity_metric='cosine'),
        'content_euclidean': ContentBasedRecommender(similarity_metric='euclidean'),
        'content_reduced': ContentBasedRecommender(similarity_metric='cosine', n_components=50),
        'tfidf_default': TFIDFRecommender(),
        'tfidf_bigrams': TFIDFRecommender(ngram_range=(1, 3)),
        'tfidf_large': TFIDFRecommender(max_features=2000)
    }
    
    return models


# Example usage
if __name__ == "__main__":
    # Example with synthetic data
    np.random.seed(42)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ synthetic –¢–æ–≤–∞—Ä features
    n_items = 100
    feature_dim = 50
    
    item_features = {
        'tfidf': {
            str(i): np.random.rand(feature_dim) 
            for i in range(n_items)
        },
        'categories': {
            str(i): np.random.choice(['electronics', 'clothing', 'books'])
            for i in range(n_items)
        }
    }
    
    # –°–æ–∑–¥–∞–Ω–∏–µ synthetic –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å-–¢–æ–≤–∞—Ä –ú–∞—Ç—Ä–∏—Ü–∞
    n_users = 200
    user_item_matrix = csr_matrix(
        np.random.rand(n_users, n_items) > 0.95
    ).astype(float)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ metadata
    metadata = {
        'item_encoder': LabelEncoder().fit(range(n_items))
    }
    
    print(f"üìä –°–æ–∑–¥–∞–Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∞—è –º–∞—Ç—Ä–∏—Ü–∞: {user_item_matrix.shape}")
    print(f"üìä –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤: {len(item_features)}")
    
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ö–æ–Ω—Ç–µ–Ω—Ç–Ω–∞—è-Based –ú–æ–¥–µ–ª—å
    cb_model = ContentBasedRecommender()
    cb_model.fit(user_item_matrix, item_features, metadata)
    
    # Get recommendations for first –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
    recommendations = cb_model.recommend_for_user(
        0, n_recommendations=5, 
        user_item_matrix=user_item_matrix
    )
    print(f"\nüéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 0:")
    for item_idx, score in recommendations:
        print(f"   –¢–æ–≤–∞—Ä {item_idx}: {score:.4f}")
    
    # Get similar items
    similar_items = cb_model.get_similar_items(0, n_similar=3)
    print(f"\nüîó –ü–æ—Ö–æ–∂–∏–µ —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Ç–æ–≤–∞—Ä 0:")
    for item_idx, score in similar_items:
        print(f"   –¢–æ–≤–∞—Ä {item_idx}: {score:.4f}")
    
    print("\n‚úÖ –¢–µ—Å—Ç –∫–æ–Ω—Ç–µ–Ω—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω")
